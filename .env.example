# Example env vars for local development - copy to .env and adjust values

FLASK_APP=app.py
FLASK_ENV=development
SECRET_KEY=replace_with_a_secure_random_string
PORT=5000
DEBUG=1

# Ollama (local model runner) configuration
# Run ollama on your host (it will use the RTX 4050). Default Ollama HTTP API port is 11434.
# Windows / Docker Desktop: use host.docker.internal
#   OLLAMA_HOST=http://host.docker.internal:11434
# Linux (recommended): run container with --network=host and use 127.0.0.1
#   docker run --network=host ... (then OLLAMA_HOST=http://127.0.0.1:11434)
OLLAMA_HOST=http://host.docker.internal:11434
# Use the 3B Llama 3.2 model
OLLAMA_MODEL=llama3.2:3b
OLLAMA_USE_GPU=true

# Example DB url (adjust to your DB): sqlite file for quick local use
DATABASE_URL=sqlite:///instance/db.sqlite
